{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T01:27:04.533365Z",
     "start_time": "2020-06-27T01:27:03.979826Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import torch\n",
    "\n",
    "from data import ScanDataset,ScanAugmentedDataset,MTDataset,SCAN_collate\n",
    "from SymbolicOperator import SymbolicOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T01:27:04.537750Z",
     "start_time": "2020-06-27T01:27:04.534870Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('vocab.json','r') as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T01:27:04.547323Z",
     "start_time": "2020-06-27T01:27:04.539718Z"
    }
   },
   "outputs": [],
   "source": [
    "in_vocab_size = len(vocab['in_token_to_idx'])\n",
    "out_vocab_size = len(vocab['out_idx_to_token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T01:27:04.571998Z",
     "start_time": "2020-06-27T01:27:04.549002Z"
    }
   },
   "outputs": [],
   "source": [
    "model = SymbolicOperator(in_vocab_size, out_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T01:27:04.585501Z",
     "start_time": "2020-06-27T01:27:04.573507Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SymbolicOperator(\n",
       "  (attention): Attention()\n",
       "  (gate_embedding): Embedding(16, 1)\n",
       "  (program_embedding): Embedding(16, 200)\n",
       "  (primitive_embedding): Embedding(16, 200)\n",
       "  (gate_linear): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (executor_rnn_cell): GRUCell(1, 384)\n",
       "  (out_linear): Linear(in_features=200, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = 'checkpoints/b043faab3a8d43d2a7ceb3ee510cd2a2'\n",
    "model.load_state_dict(torch.load(checkpoint_path, map_location=torch.device('cpu')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T01:39:39.531063Z",
     "start_time": "2020-06-27T01:39:39.448654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  4,  5, 12,  4,  8]])\n",
      "tensor([2, 2, 2, 2, 3])\n",
      "tensor([2, 2, 4, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "instruction_text = '<SOS> jump twice and walk twice <EOS>'.split()\n",
    "action_text = '<SOS> I_JUMP I_JUMP I_WALK I_WALK <EOS>'.split()\n",
    "\n",
    "instruction = []\n",
    "for i, token in enumerate(instruction_text):\n",
    "    idx = int(vocab['in_token_to_idx'][token])\n",
    "    idx = torch.tensor(idx)\n",
    "    instruction.append(idx)\n",
    "    \n",
    "action = []\n",
    "for i, token in enumerate(action_text):\n",
    "    idx = int(vocab['out_token_to_idx'][token])\n",
    "    idx = torch.tensor(idx)\n",
    "    action.append(idx)\n",
    "    \n",
    "instructions = torch.tensor([instruction])\n",
    "actions = torch.tensor([action])\n",
    "print(instructions)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output, true_actions = model(instructions, actions)\n",
    "\n",
    "true_actions = true_actions[0]\n",
    "predicted_actions = output[0].argmax(0)\n",
    "print(predicted_actions)\n",
    "print(true_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T01:27:04.714180Z",
     "start_time": "2020-06-27T01:27:04.685048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seeing jump\n",
      "read: jump\n",
      "write: tensor([1, 0, 0, 0, 0])\n",
      "['<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
      "read: jump\n",
      "write: tensor([1, 0, 0, 0, 0])\n",
      "['I_JUMP', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
      "read: jump\n",
      "write: tensor([1, 0, 0, 0, 0])\n",
      "['I_JUMP', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
      "read: jump\n",
      "write: tensor([0, 1, 0, 0, 0])\n",
      "['I_JUMP', 'I_JUMP', '<EOS>', '<EOS>', '<EOS>']\n",
      "read: jump\n",
      "write: tensor([0, 1, 0, 0, 0])\n",
      "['I_JUMP', 'I_JUMP', '<EOS>', '<EOS>', '<EOS>']\n",
      "\n",
      "seeing twice\n",
      "read: tensor([1, 0, 0, 0, 0])\n",
      "write: tensor([0, 1, 0, 0, 0])\n",
      "['I_JUMP', 'I_JUMP', '<EOS>', '<EOS>', '<EOS>']\n",
      "read: tensor([1, 0, 0, 0, 0])\n",
      "write: tensor([0, 0, 1, 0, 0])\n",
      "['I_JUMP', 'I_JUMP', '<EOS>', '<EOS>', '<EOS>']\n",
      "read: tensor([1, 0, 0, 0, 0])\n",
      "write: tensor([0, 0, 1, 0, 0])\n",
      "['I_JUMP', 'I_JUMP', 'I_JUMP', '<EOS>', '<EOS>']\n",
      "read: tensor([1, 0, 0, 0, 0])\n",
      "write: tensor([0, 0, 1, 0, 0])\n",
      "['I_JUMP', 'I_JUMP', 'I_JUMP', '<EOS>', '<EOS>']\n",
      "read: tensor([1, 0, 0, 0, 0])\n",
      "write: tensor([0, 0, 1, 0, 0])\n",
      "['I_JUMP', 'I_JUMP', 'I_JUMP', '<EOS>', '<EOS>']\n",
      "\n",
      "seeing and\n",
      "read: tensor([1, 0, 0, 0, 0])\n",
      "write: tensor([0, 0, 1, 0, 0])\n",
      "['I_JUMP', 'I_JUMP', 'I_JUMP', '<EOS>', '<EOS>']\n",
      "read: tensor([1, 0, 0, 0, 0])\n",
      "write: tensor([0, 0, 1, 0, 0])\n",
      "['I_JUMP', 'I_JUMP', 'I_JUMP', '<EOS>', '<EOS>']\n",
      "read: tensor([1, 0, 0, 0, 0])\n",
      "write: tensor([0, 0, 1, 0, 0])\n",
      "['I_JUMP', 'I_JUMP', 'I_JUMP', '<EOS>', '<EOS>']\n",
      "read: tensor([1, 0, 0, 0, 0])\n",
      "write: tensor([0, 0, 1, 0, 0])\n",
      "['I_JUMP', 'I_JUMP', 'I_JUMP', '<EOS>', '<EOS>']\n",
      "read: tensor([1, 0, 0, 0, 0])\n",
      "write: tensor([0, 0, 1, 0, 0])\n",
      "['I_JUMP', 'I_JUMP', 'I_JUMP', '<EOS>', '<EOS>']\n",
      "\n",
      "seeing walk\n",
      "read: tensor([1, 0, 0, 0, 0])\n",
      "write: tensor([0, 0, 1, 0, 0])\n",
      "['I_JUMP', 'I_JUMP', 'I_JUMP', '<EOS>', '<EOS>']\n",
      "read: tensor([1, 0, 0, 0, 0])\n",
      "write: tensor([0, 0, 1, 0, 0])\n",
      "['I_JUMP', 'I_JUMP', 'I_JUMP', '<EOS>', '<EOS>']\n",
      "read: tensor([1, 0, 0, 0, 0])\n",
      "write: tensor([0, 0, 1, 0, 0])\n",
      "['I_JUMP', 'I_JUMP', 'I_JUMP', '<EOS>', '<EOS>']\n",
      "read: tensor([1, 0, 0, 0, 0])\n",
      "write: tensor([0, 0, 1, 0, 0])\n",
      "['I_JUMP', 'I_JUMP', 'I_JUMP', '<EOS>', '<EOS>']\n",
      "read: tensor([1, 0, 0, 0, 0])\n",
      "write: tensor([0, 0, 1, 0, 0])\n",
      "['I_JUMP', 'I_JUMP', 'I_JUMP', '<EOS>', '<EOS>']\n",
      "\n",
      "seeing twice\n",
      "read: tensor([1, 0, 0, 0, 0])\n",
      "write: tensor([0, 0, 1, 0, 0])\n",
      "['I_JUMP', 'I_JUMP', 'I_JUMP', 'I_JUMP', '<EOS>']\n",
      "read: tensor([1, 0, 0, 0, 0])\n",
      "write: tensor([0, 0, 1, 0, 0])\n",
      "['I_JUMP', 'I_JUMP', 'I_JUMP', 'I_JUMP', '<EOS>']\n",
      "read: tensor([1, 0, 0, 0, 0])\n",
      "write: tensor([0, 0, 1, 0, 0])\n",
      "['I_JUMP', 'I_JUMP', 'I_JUMP', 'I_JUMP', '<EOS>']\n",
      "read: tensor([1, 0, 0, 0, 0])\n",
      "write: tensor([0, 0, 1, 0, 0])\n",
      "['I_JUMP', 'I_JUMP', 'I_JUMP', 'I_JUMP', '<EOS>']\n",
      "read: tensor([1, 0, 0, 0, 0])\n",
      "write: tensor([0, 0, 1, 0, 0])\n",
      "['I_JUMP', 'I_JUMP', 'I_JUMP', 'I_JUMP', '<EOS>']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scratch_history = []\n",
    "for word in model.scratch_history:\n",
    "    scratch_history.append([])\n",
    "    for step in word:\n",
    "        gate = step[0][0][0].item()\n",
    "        read = step[1][0][0].long()\n",
    "        write = step[2][0][0].long()\n",
    "        scratch = step[3].argmax(-1)[0]\n",
    "        scratch_history[-1].append([gate, read, write, scratch])\n",
    "\n",
    "for i, steps in enumerate(scratch_history):\n",
    "    word = instruction_text[i+1]\n",
    "    print('seeing', word)\n",
    "    for gate, read, write, scratch_pad in steps:\n",
    "        tokens = []\n",
    "        for token_idx in scratch_pad:\n",
    "            token = vocab['out_idx_to_token'][str(token_idx.item())]\n",
    "            tokens.append(token)\n",
    "        if gate == 1:\n",
    "            print('read:', word)\n",
    "        else:\n",
    "            print('read:', read)\n",
    "        print('write:', write)\n",
    "        print(tokens)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T01:27:04.726753Z",
     "start_time": "2020-06-27T01:27:04.716042Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor([[1.]]),\n",
       "  tensor([[[1., 0., 0., 0., 0.]]]),\n",
       "  tensor([[[1., 0., 0., 0., 0.]]]),\n",
       "  tensor([[[-4.3914, -4.4068,  2.8510,  3.4906, -1.8638, -3.9698, -3.7215,\n",
       "            -3.3059],\n",
       "           [-5.1195, -5.1162, -2.4968,  7.8235, -0.1476, -4.6568, -4.3110,\n",
       "            -2.7688],\n",
       "           [-5.2455, -5.2389, -3.4220,  8.5731,  0.1493, -4.7756, -4.4130,\n",
       "            -2.6759],\n",
       "           [-5.2466, -5.2400, -3.4303,  8.5799,  0.1519, -4.7767, -4.4139,\n",
       "            -2.6751],\n",
       "           [-5.2466, -5.2400, -3.4304,  8.5799,  0.1520, -4.7767, -4.4139,\n",
       "            -2.6751]]])],\n",
       " [tensor([[1.]]),\n",
       "  tensor([[[1., 0., 0., 0., 0.]]]),\n",
       "  tensor([[[1., 0., 0., 0., 0.]]]),\n",
       "  tensor([[[-3.8433, -3.8727,  6.8773,  0.2284, -3.1558, -3.4526, -3.2776,\n",
       "            -3.7102],\n",
       "           [-5.1164, -5.1131, -2.4741,  7.8051, -0.1549, -4.6539, -4.3085,\n",
       "            -2.7711],\n",
       "           [-5.2455, -5.2389, -3.4220,  8.5731,  0.1493, -4.7756, -4.4130,\n",
       "            -2.6759],\n",
       "           [-5.2466, -5.2400, -3.4303,  8.5799,  0.1519, -4.7767, -4.4139,\n",
       "            -2.6751],\n",
       "           [-5.2466, -5.2400, -3.4304,  8.5799,  0.1520, -4.7767, -4.4139,\n",
       "            -2.6751]]])],\n",
       " [tensor([[1.]]),\n",
       "  tensor([[[1., 0., 0., 0., 0.]]]),\n",
       "  tensor([[[1., 0., 0., 0., 0.]]]),\n",
       "  tensor([[[-3.5742, -3.6104,  8.8543, -1.3734, -3.7902, -3.1986, -3.0597,\n",
       "            -3.9088],\n",
       "           [-5.1039, -5.1010, -2.3822,  7.7307, -0.1844, -4.6421, -4.2984,\n",
       "            -2.7803],\n",
       "           [-5.2454, -5.2388, -3.4217,  8.5729,  0.1492, -4.7756, -4.4130,\n",
       "            -2.6759],\n",
       "           [-5.2466, -5.2400, -3.4303,  8.5799,  0.1519, -4.7767, -4.4139,\n",
       "            -2.6751],\n",
       "           [-5.2466, -5.2400, -3.4304,  8.5799,  0.1520, -4.7767, -4.4139,\n",
       "            -2.6751]]])],\n",
       " [tensor([[1.]]),\n",
       "  tensor([[[1., 0., 0., 0., 0.]]]),\n",
       "  tensor([[[0., 1., 0., 0., 0.]]]),\n",
       "  tensor([[[-3.5590, -3.5956,  8.9659, -1.4638, -3.8261, -3.1843, -3.0474,\n",
       "            -3.9200],\n",
       "           [-3.7054, -3.7384,  7.8899, -0.5920, -3.4808, -3.3225, -3.1660,\n",
       "            -3.8119],\n",
       "           [-5.1607, -5.1563, -2.7997,  8.0690, -0.0504, -4.6957, -4.3444,\n",
       "            -2.7384],\n",
       "           [-5.2464, -5.2398, -3.4290,  8.5789,  0.1515, -4.7765, -4.4138,\n",
       "            -2.6752],\n",
       "           [-5.2466, -5.2400, -3.4304,  8.5799,  0.1520, -4.7767, -4.4139,\n",
       "            -2.6751]]])],\n",
       " [tensor([[1.]]),\n",
       "  tensor([[[1., 0., 0., 0., 0.]]]),\n",
       "  tensor([[[0., 1., 0., 0., 0.]]]),\n",
       "  tensor([[[-3.5499, -3.5868,  9.0326, -1.5179, -3.8475, -3.1757, -3.0400,\n",
       "            -3.9267],\n",
       "           [-3.4708, -3.5097,  9.6134, -1.9884, -4.0338, -3.1011, -2.9760,\n",
       "            -3.9850],\n",
       "           [-5.0373, -5.0361, -1.8931,  7.3344, -0.3414, -4.5792, -4.2445,\n",
       "            -2.8294],\n",
       "           [-5.2461, -5.2395, -3.4266,  8.5769,  0.1507, -4.7762, -4.4135,\n",
       "            -2.6754],\n",
       "           [-5.2466, -5.2400, -3.4304,  8.5799,  0.1519, -4.7767, -4.4139,\n",
       "            -2.6751]]])]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.scratch_history[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
